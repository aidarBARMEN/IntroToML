{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcc3f001-88f1-475b-bf5a-5f0d1ca844a9",
   "metadata": {},
   "source": [
    "# Part 1:\n",
    "\n",
    "1) Give 1 real world example for:\n",
    "   - Binary Classification Task\n",
    "   - Multiclass Classification Task\n",
    "   - Regression Task\n",
    "\n",
    "Answer: as I understood, binary classification is a task where we can devide answers into 2 like TRUE OR FALSE; F.e: Dog or not\n",
    "Multiclass is where we should pick 1 of 3 more classes. For exaple: I did a project where we should do desicion is it 1,2,3,4,5,6,7,8,9,0 in paper\n",
    "Regression: where we should predict in advance like price of the car if we have some parameterers for example: Year, house power etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d533bd41",
   "metadata": {},
   "source": [
    "2)\n",
    "Classifying into 2 classes, a model produces the following outputs:\n",
    "\n",
    "\n",
    "| $y_i$     |               $\\hat{y_i}$                                  |\n",
    "|---------|----------------------------------------------------------|\n",
    "| 1       | 0.9 |\n",
    "| 1       | 0.4 |\n",
    "| 0       | 0.3 |\n",
    "| 0       | 0.6 |\n",
    "\n",
    "Calculate the binary cross-entropy loss.\n",
    "firsly formula: H(y,p) = -[y*log(p) + (1-y)*log(1-p)] where log() -> ln\n",
    "y=1; p=0.9: -(1*log(0,9) + (1-0,9)* log(1-,09)) = -(-0,1054) = 0,105\n",
    "y=1; p=0,4: -(1*log(0,4) + 0,6 * log(0,6)) =  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1f846a",
   "metadata": {},
   "source": [
    "3) While improving a model complexity, if you notice that a model's training error is decreasing but the test error is getting higher, what does this indicate about the model's behavior?\n",
    "\n",
    "Answer: it indicates - overfitting. The model is learning more than it should and it is sensitive to tiny fluctuations in the training data.\n",
    "Regularization, reducing model complexity, increasing the amount of data, or cross validation can be used to solve the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75d5f95",
   "metadata": {},
   "source": [
    "4. Suppose we have a dataset with categorical targets $Y = ${$1, ..., K$}. \n",
    "\n",
    "Let $n_k$ be the size of the $k$-th category :\n",
    "\n",
    "$$\n",
    "n_k = \\sum_{i=1}^{n} \\mathbb{I}[y_i = k], \\quad \\sum_{k=1}^{K} n_k = n.\n",
    "$$\n",
    "\n",
    "Consider a dummy model which always predicts category $l$, $1<l<K$. What is the value of the error rate ? For which $l$\n",
    " it is minimal?\n",
    "\n",
    " errorrate = errorsamount/objectsamount\n",
    " If the model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03be6d8c",
   "metadata": {},
   "source": [
    "5. The MSE for a constant model $f_\\theta(x_i) = c$ is given by : \n",
    "\n",
    "$$\n",
    "\\frac{1}{n} \\sum_{i=1}^{n} (y_i - c)^2.\n",
    "$$\n",
    "\n",
    "Find the constant $c$ that minimizes the MSE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f73a6e-7bf3-4ede-9e06-7a392d56dd86",
   "metadata": {},
   "source": [
    "# Part 2:\n",
    "\n",
    "### Step 1 : Generate synthetic data (Y) following any type of distributions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d1ee72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43873931",
   "metadata": {},
   "source": [
    "### Step 2 : Define a function to compute MSE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd08011e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7141b73",
   "metadata": {},
   "source": [
    "### Step 3 : Find the optimal c, compare it to the mean of you synthetic dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22abbdba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4010751b",
   "metadata": {},
   "source": [
    "### Step 4 : Plot the MSE curve and the optimal c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38ba4fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75812aca",
   "metadata": {},
   "source": [
    "# Part 3 : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d6a762",
   "metadata": {},
   "source": [
    "Write your own implementation of splitting the dataset on train and test using shuffling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a7e159-1c4d-4514-ab76-9fcf047fa4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Split the dataset into training and testing sets.\n",
    "\n",
    "    Parameters:\n",
    "    X (numpy array): The feature matrix.\n",
    "    y (numpy array): The target labels.\n",
    "    test_size (float): The proportion of the dataset to include in the test split.\n",
    "\n",
    "    Returns:\n",
    "    X_train (numpy array): The training feature matrix.\n",
    "    X_test (numpy array): The testing feature matrix.\n",
    "    y_train (numpy array): The training labels.\n",
    "    y_test (numpy array): The testing labels.\n",
    "    \"\"\"\n",
    "\n",
    "    # YOUR CODE GOES HERE\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8]]\n",
    "y = [0, 1, 0, 1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4257ffdc-f52c-4dc7-82a2-e23875811fae",
   "metadata": {},
   "source": [
    "Run the following tests to ensure that your implementation works as expected. <br>\n",
    "<strong>Don't modify the cells</strong>!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbd7f9b-74a3-4f66-9b09-f9bc778cb27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_basic_split():\n",
    "    X = [[1, 2], [3, 4], [5, 6], [7, 8]]\n",
    "    y = [0, 1, 0, 1]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "    \n",
    "    # Check if the correct number of samples is in the train and test sets\n",
    "    assert len(X_train) == 3, f\"Expected 3 training samples, got {len(X_train)}\"\n",
    "    assert len(X_test) == 1, f\"Expected 1 test sample, got {len(X_test)}\"\n",
    "    assert len(y_train) == 3, f\"Expected 3 training labels, got {len(y_train)}\"\n",
    "    assert len(y_test) == 1, f\"Expected 1 test label, got {len(y_test)}\"\n",
    "    \n",
    "    print(\"Basic split test passed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c166f7f-8c18-4b72-aa2c-d09b8b6ea2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_empty_dataset():\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "    \n",
    "    # Check if the splits are empty\n",
    "    assert len(X_train) == 0, f\"Expected 0 training samples, got {len(X_train)}\"\n",
    "    assert len(X_test) == 0, f\"Expected 0 test samples, got {len(X_test)}\"\n",
    "    assert len(y_train) == 0, f\"Expected 0 training labels, got {len(y_train)}\"\n",
    "    assert len(y_test) == 0, f\"Expected 0 test labels, got {len(y_test)}\"\n",
    "    \n",
    "    print(\"Empty dataset test passed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704d03fe-649c-4cd5-a7f2-fcbd3c0e2178",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_different_test_size():\n",
    "    X = [[1, 2], [3, 4], [5, 6], [7, 8]]\n",
    "    y = [0, 1, 0, 1]\n",
    "    \n",
    "    # Test with 50% test size\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
    "    assert len(X_test) == 2, f\"Expected 2 test samples, got {len(X_test)}\"\n",
    "    \n",
    "    # Test with 25% test size\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "    assert len(X_test) == 1, f\"Expected 1 test sample, got {len(X_test)}\"\n",
    "    \n",
    "    print(\"Different test_size values test passed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f6cd9a-62cb-4a5f-a225-dc46e9fa3082",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data = load_iris()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "def test_real_dataset():\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "    \n",
    "    # Check the size of the train and test sets\n",
    "    assert len(X_train) == 105, f\"Expected 105 training samples, got {len(X_train)}\"\n",
    "    assert len(X_test) == 45, f\"Expected 45 test samples, got {len(X_test)}\"\n",
    "    \n",
    "    print(\"Real dataset test passed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e78a79c-fe17-444e-a7da-190fc9aeb2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tests():\n",
    "    test_basic_split()\n",
    "    test_empty_dataset()\n",
    "    test_different_test_size()\n",
    "    test_real_dataset()\n",
    "\n",
    "run_tests()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
